{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Charles-Reddit Post Controversiality- Revised version .ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwcALpuJ4fSV"
      },
      "source": [
        "#Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6gBBZUzs4jSK",
        "outputId": "5e00fc7b-102b-4919-cbc0-b5c92472f706"
      },
      "source": [
        "#Load Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sb\n",
        "import keras as ks\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import pathlib\n",
        "from pandas import read_csv\n",
        "from pandas.plotting import scatter_matrix\n",
        "from matplotlib import pyplot as plt\n",
        "from matplotlib.pyplot import figure\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import  DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from matplotlib import cm\n",
        "%matplotlib inline\n",
        "\n",
        "!gdown --id 1Q0HAXTixzFzl7eOAZbuXxrhvMCFMoRKL -O marchsample"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Q0HAXTixzFzl7eOAZbuXxrhvMCFMoRKL\n",
            "To: /content/marchsample\n",
            "583MB [00:09, 64.4MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5oSeygGg4luc",
        "outputId": "91067a28-e946-490a-e74e-6dc33a5740ff"
      },
      "source": [
        "#store everything in a dataframe\n",
        "reddit_df = pd.read_json(\"marchsample\",lines=True)\n",
        "#shape of dataset\n",
        "print(\"Shape of the dataset without preprocessing is \",reddit_df.shape)\n",
        "#columns of dataset \n",
        "print(\"Columns in reddit dataset \", reddit_df.columns)\n",
        "#statistical analysis of dataset\n",
        "print(reddit_df.describe())\n",
        "#types\n",
        "print(reddit_df.dtypes)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of the dataset without preprocessing is  (1000000, 18)\n",
            "Columns in reddit dataset  Index(['ups', 'author_flair_text', 'gilded', 'author', 'created_utc', 'id',\n",
            "       'score', 'distinguished', 'parent_id', 'retrieved_on', 'link_id',\n",
            "       'author_flair_css_class', 'subreddit_id', 'body', 'subreddit',\n",
            "       'stickied', 'controversiality', 'edited'],\n",
            "      dtype='object')\n",
            "                  ups          gilded  ...  controversiality        edited\n",
            "count  1000000.000000  1000000.000000  ...    1000000.000000  1.000000e+06\n",
            "mean         5.234093        0.000252  ...          0.023050  4.766906e+07\n",
            "std         48.146464        0.017028  ...          0.150062  2.591869e+08\n",
            "min       -429.000000        0.000000  ...          0.000000  0.000000e+00\n",
            "25%          1.000000        0.000000  ...          0.000000  0.000000e+00\n",
            "50%          1.000000        0.000000  ...          0.000000  0.000000e+00\n",
            "75%          3.000000        0.000000  ...          0.000000  0.000000e+00\n",
            "max       6046.000000        4.000000  ...          1.000000  1.460343e+09\n",
            "\n",
            "[8 rows x 7 columns]\n",
            "ups                        int64\n",
            "author_flair_text         object\n",
            "gilded                     int64\n",
            "author                    object\n",
            "created_utc                int64\n",
            "id                        object\n",
            "score                      int64\n",
            "distinguished             object\n",
            "parent_id                 object\n",
            "retrieved_on               int64\n",
            "link_id                   object\n",
            "author_flair_css_class    object\n",
            "subreddit_id              object\n",
            "body                      object\n",
            "subreddit                 object\n",
            "stickied                    bool\n",
            "controversiality           int64\n",
            "edited                     int64\n",
            "dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vqs8lny84nZn",
        "outputId": "344f7ac2-087d-4038-d0d6-6774b85978ca"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "np.sum((reddit_df[\"body\"].apply(len)> 500) & (reddit_df[\"controversiality\"]==1))\n",
        "redditdflong = reddit_df[(reddit_df[\"body\"].apply(len)> 1000)]\n",
        "df_controversial_long = redditdflong[redditdflong[\"controversiality\"]==1]\n",
        "df_noncontroversial_long = redditdflong[redditdflong[\"controversiality\"]==0].sample(536)\n",
        "df_testbalanced = pd.concat([df_controversial_long, df_noncontroversial_long], axis=0)\n",
        "df_testbalanced.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1072, 18)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2GlN8fJ74p7O",
        "outputId": "047d8ea5-c8f7-4c79-e575-f18adfb63e3e"
      },
      "source": [
        "#dropping everything.\n",
        "redditdf2 = df_testbalanced.drop(['author_flair_text', 'edited', 'parent_id', 'subreddit_id',\n",
        "        'id', 'distinguished', 'retrieved_on', 'created_utc',\n",
        "       'link_id', 'author_flair_css_class', 'stickied', 'gilded', 'author',\n",
        "       'score', 'ups'], axis=1)\n",
        "print(redditdf2.columns)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['body', 'subreddit', 'controversiality'], dtype='object')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJ51cxQ-4uGC",
        "outputId": "b15b5369-3e98-4c9b-e25c-087d91a25032"
      },
      "source": [
        "#removing [removed] section from the body part.\n",
        "redditdf2_clean = redditdf2[~redditdf2['body'].str.contains('removed')]\n",
        "redditdf2_clean.reset_index(drop=True, inplace=True)\n",
        "redditdf2_clean.values"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[\"HC is **not** to the left on income inequality, minimum wage, healthcare, financial reform, at all. She is most firmly entrenched with the banks and corporations that created it. Abortion rights, gay rights, and other social issues are just the bones she will throw to us. She doesn't support them, and has never supported them unless they were politically expedient for her. She'd toss them under a bus if it would get her votes. \\n\\nI don't know where you were in the 90's, and what you saw during the Clinton administration. What I saw was a non-stop capitulation of liberal values. It felt like every time it came to a showdown, the Dems capitulated. HC pushed healthcare reform in the first term. But she kept blinking, and waiting until '94, when the Rs took control of the house. Then she dropped it like a hot potato and it took *another 14 years* before the Dems would touch it again. So don't play me that snake oil. \\n\\n&gt; you cannot in good conscience abstain or vote GOP.\\n\\nI never said that, so stop putting words in my mouth or setting me up for a false choice. You're slick, I'll give you that. I don't know how much the HC campaign is paying you, but you should get paid. You're very articulate and you frame the issues like a pro.\\n\\nBut this is my main point: America is in a deeper crisis now than it was before the Civil War. Clinton is the only sane candidate that is also driving the crisis. Rubio, Cruz, and Trump, they're just plain nuts, and that's why CitiBank and the rest are pouring their cash into Clinton. \\n\\nWhich is why if she is elected, poverty will continue to overtake the middle class as it has done since Reagan, lip service will be paid to climate change, but nothing substantial will be done, the massive subsidies to fossil fuels will remain intact, the cash flow off-shore will continue, essentially nothing will change, except people will get more and more pissed off. What her campaign fails to realize is that the old hypocrisy doesn't fly anymore. Your tactic of waving the Republican boogie-man is becoming weak. People want a real liberal, and are tired of the Reagan-in-Dem clothing that the Clintons and their power base have been waving for decades. \",\n",
              "        'Liberal', 1],\n",
              "       ['**\"It\\'s more just a different kind of bigotry. Let\\'s not forget that there is a \"special place in hell\" for young women who don\\'t vote for Hillary because she\\'s a woman.\"[+87]**\\n\\n---\\n\\nIn reply to matt526 on [\"\"Why do voters need to know what Hillary told the banks? Because it was Wall Street that was responsible for the 2008 recession, making life worse for most Americans. We need to know what, if anything, she promised these behemoths.\"\"](http://www.reddit.com/r/politics/comments/48aq7h):\\n\\n&gt; Turns out democrats unfortunately just want a Republican president without the bigotry. \\n\\nAt 2016-02-29 15:56:19 UTC, boogietime wrote [+90 points: +90, -0]:\\n\\n&gt; It\\'s more just a different kind of bigotry.  Let\\'s not forget that there is a \"special place in hell\" for young women who don\\'t vote for Hillary because she\\'s a woman.\\n\\n[Screenshot](http://i.imgur.com/oaE9iSl.png)\\n\\n[Vote History on srscharts](http://74.207.230.31/srscharts/#d0i4w79)\\n\\n&amp;nbsp;^This&amp;nbsp;comment&amp;nbsp;posted&amp;nbsp;by&amp;nbsp;a&amp;nbsp;bot&amp;nbsp;|&amp;nbsp;[Report&amp;nbsp;an&amp;nbsp;error](http://www.reddit.com/message/compose/?to=SRScreenshot&amp;subject=Bug%20report&amp;message=%5BComment%20thread%5D%28https%3A//www.reddit.com/r/ShitRedditSays/comments/48de12/its_more_just_a_different_kind_of_bigotry_lets/%29%0A%0APlease%20add%20any%20additional%20comments%20below.%0A%0A)&amp;nbsp;|&amp;nbsp;[FAQ](/r/SRScreenshot/wiki/faq)',\n",
              "        'ShitRedditSays', 1],\n",
              "       ['Look, I had a whole thing typed out explaining it, but let me just cut to the point, because I think you\\'re touching on what I\\'m getting at.\\n\\nIf the old bakery closed, and no one else makes that cake anymore, then why the fuck are people getting pissed off at the new baker for trying when they\\'re all bitching about someone making a cake that can\\'t be made anymore?  It will never be... because the old bakery is closed.  But the customers keep fucking yelling about it, so why not try something?\\n\\nYou said it yourself: The old bakery closed and no one makes the cake anymore.  You can no longer have that cake from when you were 5.  Because it\\'s a different time and people are different and in different places.\\n\\nThe real question is, if that\\'s the truth about the situation, then why does it offend you so badly that they are taking the topper and using it on other cakes?  And why are people assuming that makes the new cake bad instead of just different than the old cake?\\n\\nThis is something Nintendo has been doing since the beginning and no one bats an eye: use the same topper on different cakes.  Make the cake, make it good, throw on a topper people know and love.  People eat that shit up.\\n\\nNow people are assuming the cake is shitty because the topper is on a different cake.\\n\\nSeriously, people are bitching over an early preview of something FUCKING AMAZING because it\\'s conker and it looks weird and people don\\'t want anything but the old game again...\\n\\nJust like you\\'re doing here.  You\\'re calling it a:\\n\\n&gt; fucking fruit cobbler and throw the themed character topper from your fifth birthday party on top and say \"see? Isn\\'t this what you wanted?\" \\n\\nBut you\\'ve literally only seen an early preview with the focus on the topper... not even the cake.  But you are judging the cake like you\\'re a professional cake critic.',\n",
              "        'Games', 1],\n",
              "       ...,\n",
              "       [\"I've found myself referring to [this](http://www.ratbehavior.org) website a lot when researching things about my rats. When you do get your lil' guy a friend and do the introductions and bonding process, there's a lot of useful information about aggressive and play fighting and how to tell them apart. \\n\\nAdditionally, all the links in the side bar can be great resources. I've gleaned a lot of information just from reading posts by other people on some of the rats forums listed. A lot of the questions you have will probably be out there somewhere and will have been answered; it just requires a lil' looking, which may be easier or quicker than waiting for response here (I am a big fan of instant gratification). I know I've found a lot of great advice about things like food and litter training and fleece liners and such on Goosemoose threads that show up when I search my questions through google. \\n\\nAdditionally, your rats are probably gonna do a bunch of silly things that haven't been written about out there. Rats are just goofty and quirky lil' creatures. The main things behaviorally to be concerned with are signs of illness and signs of aggression. Sometimes they might stare into space weirdly or seem randomly startled; thats okay. Their senses of smell and hearing are WAY more sensitive than we could possibly imagine. Sometimes something as simple as a cry from a bird of prey that we can't even hear will put a rat on edge for an afternoon. \\n\\nPrimarily you want to make sure they seem attentive and energetic with normal appetites, thirst levels, and breathing. And if your pair seems to be exhibiting aggression towards one another, I'd keep a close eye out for injuries. The general rule though, for rat fights, is no blood, no foul. Intervening preemptively may only make the process more difficult in the long run. The occasional nick or scrape probably isn't a huge deal (although it may indicate that someone needs a nail trim) and rats tend to heal pretty fast, but I'd be pretty wary if any more significant injuries happen. Often with male, aggression that results injury will require that the instigator at least (if not both) be neutered. \\n\\nFrom your other post, it sounds like you are planning on doing this regardless, which will definitely make aggression from your boy MUCH less likely. \\n\\nAs a bonus for getting through another wall of my text, here are some pictures of [girls](http://imgur.com/a/lWfRn) cuddling in a hammock, cause yeah, they're pretty cute.\",\n",
              "        'RATS', 0],\n",
              "       ['\\n# *BOOK━READ \"Greenmantle by John Buchan\"  reader ios djvu online sale selling torrent eng*\\n\\n\\n***\\n## █ ► [**READ** ***Greenmantle by John Buchan***](https://bzgnnbab.bzgnnbab.su/60bY?source=reddit2&amp;keyword=Greenmantle%20by%20John%20Buchan)\\n***\\n***\\n## █ ► [**ONLINE** ***Greenmantle by John Buchan***](https://bzgnnbab.bzgnnbab.su/60bY?source=reddit2&amp;keyword=Greenmantle%20by%20John%20Buchan)\\n***\\n***\\n## █ ► [**DOWNLOAD** ***Greenmantle by John Buchan***](https://bzgnnbab.bzgnnbab.su/60bY?source=reddit2&amp;keyword=Greenmantle%20by%20John%20Buchan)\\n***\\n\\n. \\n\\n***\\n## █ ► [**READ** ***Greenmantle by John Buchan***](https://bzgnnbab.bzgnnbab.su/60bY?source=reddit2&amp;keyword=Greenmantle%20by%20John%20Buchan)\\n***\\n***\\n## █ ► [**ONLINE** ***Greenmantle by John Buchan***](https://bzgnnbab.bzgnnbab.su/60bY?source=reddit2&amp;keyword=Greenmantle%20by%20John%20Buchan)\\n***\\n***\\n## █ ► [**DOWNLOAD** ***Greenmantle by John Buchan***](https://bzgnnbab.bzgnnbab.su/60bY?source=reddit2&amp;keyword=Greenmantle%20by%20John%20Buchan)\\n***\\n\\n&gt; . \\n\\n&gt;  Description book **Greenmantle by John Buchan**:\\n\\n&gt;  I first read this book when I was 10 or 11. It was a library copy, borrowed from the Kodaikanal Club in Kodaikanal, a hill station in south India. It used to be the local English club and the contents of the library still include a large number of old hardbound editions of authors who were popular in the Victorian and Edwardian eras. Early on in this novel, Hannay remarks on the ability of the Engl...\\n\\n&gt; .\\n\\n&gt; .\\n\\n&gt; .\\n\\n&gt; . \\n\\n&gt; .\\n\\n&gt; .\\n\\n&gt; .\\n\\n&gt; .\\n\\n&gt; .\\n\\n&gt; .\\n\\n&gt; .\\n\\n&gt; .\\n\\n&gt; [BOOK━FULL.. \"Nicholas.. and.. Alexandra.. by.. Robert.. K... Massie\".. .. eReader.. eng.. without.. signing.. story.. acquire.. mp3](https://www.reddit.com/48em59),.. [BOOK━FREE.. \"The.. Group.. by.. Mary.. McCarthy\".. .. view.. no.. registration.. torrent.. offline.. android.. selling](https://www.reddit.com/48em3u),.. [BOOK━DOWNLOAD.. \"The.. Power.. of.. One.. by.. Bryce.. Courtenay\".. .. find.. macbook.. story.. for.. review.. buy.. no.. registration.. iphone](https://www.reddit.com/48em37),.. [BOOK━ONLINE.. \"Alanna.. by.. Tamora.. Pierce\".. .. français.. full.. iBooks.. sale.. fb2.. book.. story.. thepiratebay](https://www.reddit.com/48em3e),.. [BOOK━FULL.. \"Democracy.. and.. Education.. by.. John.. Dewey\".. .. apple.. ebay.. thepiratebay.. read.. without.. signing.. ios](https://www.reddit.com/48em0t),.. [BOOK━ONLINE.. \"Cards.. on.. the.. Table.. by.. Agatha.. Christie\".. .. phone.. link.. selling.. torrent.. acquire.. no.. registration](https://www.reddit.com/48elzx),.. [BOOK━READ.. \"Freckle.. Juice.. by.. Judy.. Blume\".. .. thepiratebay.. ebay.. download.. no.. registration.. mp3.. original](https://www.reddit.com/48emak),.. [BOOK━DOWNLOAD.. \"All.. Quiet.. on.. the.. Western.. Front.. by.. Erich.. Maria.. Remarque\".. .. epub.. authors.. portable.. format.. android.. no.. registration](https://www.reddit.com/48em1o),.. [BOOK━READ.. \"The.. Mystery.. at.. Lilac.. Inn.. by.. Carolyn.. Keene\".. .. how.. to.. german.. without.. registering.. free.. finder.. find.. price](https://www.reddit.com/48em86),.. [BOOK━DOWNLOAD.. \"The.. Fire.. Next.. Time.. by.. James.. Baldwin\".. .. itunes.. tablet.. direct.. link.. apple.. français.. ios.. touch](https://www.reddit.com/48em00)\\n\\n&gt; .\\n\\n&gt; .\\n\\n&gt; Greenmantle \\n(Version \\n2) \\nby \\nJohn \\nBuchan\\nGreenmantle \\n(Illustrated) \\neBook \\nJohn \\nBuchan \\nAmazon\\nThe \\nProject \\nGutenberg \\nEBook \\nof \\nGreenmantle \\nby \\nJohn \\nBuchan \\nThis \\neBook \\nis \\nfor \\nthe \\nuse \\nof \\nanyone \\nanywhere \\nat \\nno \\ncost \\nand \\nwith \\nalmost \\nno \\nrestrictions \\nwhatsoever.\\nJohn \\nBuchan \\n1st \\nBaron \\nTweedsmuir \\nGCMG \\nGCVO \\nCH \\nPC \\n(/ˈbʌxən/; \\n26 \\nAugust \\n1875 \\n– \\n11 \\nFebruary \\n1940) \\nwas \\na \\nScottish \\nnovelist \\nhistorian \\nand \\nUnionist \\npolitician \\nwho\\nThe \\nsequel \\nto \\nThe \\nThirty \\nNine \\nSteps \\n! \\nGreenmantle \\nis \\nthe \\nsecond \\nof \\nfive \\nnovels \\nby \\nJohn \\nBuchan \\nfeaturing \\nthe \\ncharacter \\nof \\nRichard \\nHannay. \\nHannay \\nis \\ncalled \\nin \\nto\\nGreenmantle \\nby \\nJohn \\nBuchan\\nGreenmantle \\nby \\nJohn \\nBuchan \\n- \\nFree-eBooks.net \\n| \\nDownload\\nGreenmantle \\nAmazon.co.uk \\nJohn \\nBuchan \\nBooks\\nLibriVox \\nrecording \\nof \\nGreenmantle \\nby \\nJohn \\nBuchan. \\nGreenmantle \\nis \\nthe \\nsecond \\nof \\nfive \\nRichard \\nHannay \\nnovels \\nby \\nJohn \\nBuchan \\nfirst \\npublished \\nin \\n1916 \\nby\\nThe \\nProject \\nGutenberg \\nE-text \\nof \\nGreenmantle \\nby \\nJohn \\nBuchan\\ngreenmantle \\nby \\njohn \\nbuchan\\nGreenmantle \\nby \\nJohn \\nBuchan. \\nISBN \\n9781512177619\\ngreenmantle \\nby \\njohn \\nbuchanan\\ngreenmantle \\njohn \\nbuchan \\naudiobook\\ngreenmantle \\nby \\njohn \\nbuchan \\nwikipedia\\nLibriVox \\nrecording \\nof \\nGreenmantle \\n(Version \\n2) \\nby \\nJohn \\nBuchan. \\nRead \\nin \\nEnglish \\nby \\nTom \\nWeiss \\nGreenmantle \\nis \\nthe \\nsecond \\nof \\nfive \\nRichard \\nHannay \\nnovels \\nby \\nJohn\\ngreenmantle \\nby \\njohn \\nbuchan \\nbooks\\n\"Greenmantle\" \\nby \\nJohn \\nBuchan \\nis \\nactually \\nbased \\non \\na \\nremarkable \\nif \\nlittle-known \\naspect \\nof \\nGerman \\npropaganda \\nduring \\nWorld \\nWar \\nI. \\nIt \\ninvolved \\nKaiser \\nWilhelm\\nGreenmantle \\n- \\nJohn \\nBuchan \\n| \\nFeedbooks\\ngreenmantle \\njohn \\nbuchan \\nonline\\nBuy \\nGreenmantle \\nby \\nfrom \\nAmazon \\nUK’s \\nBooks \\nShop. \\nFree \\ndelivery \\non \\neligible \\norders.\\nAmazon \\nGreenmantle \\n(9781920265632) \\nJohn \\nBuchan \\nBooks\\ngreenmantle \\nby \\njohn \\nbuchan \\nquotes\\nGet \\nprices \\nfor \\nGreenmantle \\nby \\nJohn \\nBuchan. \\nPrice \\nincludes \\ndelivery. \\nISBN \\n9781512177619 \\n- \\nor \\nsearch \\nfor \\nother \\nbooks \\nin \\n-Classics\\nGreenmantle \\nJohn \\nBuchan \\nAmazon \\nBooks\\ngreenmantle \\njohn \\nbuchan \\namazon\\ngreenmantle \\njohn \\nbuchan \\narcher\\ngreenmantle \\nby \\njohn \\nbuchan \\nhomes\\nGreenmantle \\n[John \\nBuchan] \\non \\nAmazon. \\n*FREE* \\nshipping \\non \\nqualifying \\noffers.\\ngreenmantle \\nby \\njohn \\nbuchan \\nnovels\\nDownload \\nthe \\n\"Greenmantle\" \\nebook \\nfor \\nFREE. \\nRead \\nand \\nwrite \\nreviews \\nand \\nmore\\ngreenmantle \\nby \\njohn \\nbuchan \\nauthor\\n\\n&gt; .',\n",
              "        'hsupport', 0],\n",
              "       ['## [Other Subreddits / Related Links](#icon-lightbulb) \\n* General Houston:\\n  * [Young Houstonian Redditors](http://www.facebook.com/home.php?sk=group_185273774827945)\\n  * [Houston Beer](/r/HoustonBeer/)\\n  * [Houston Food](/r/Houstonfood/)\\n  * [Houston Ents](/r/houstonents)\\n  * [Houston Jobs](/r/houstonjobs)\\n  * [Houston Classifieds](/r/HoustonClassifieds)\\n  * [Houston Music](/r/houstonmusic)\\n  * [Houston Events](/r/houstonevents)\\n  * [Houston r4r](/r/houstonr4r)\\n  * [Houston Circlejerk](/r/houstoncirclejerk)\\n  * [Houston Geeks](/r/houstongeeks)\\n  * [Vegan Houston](/r/veganhouston)\\n  * [Houston History](/r/houstonhistory)\\n  * [Houston Photography](/r/houstonphotography)\\n  * [Houston Entrepreneurs](/r/HoustonEntrepreneurs)\\n  * [Frugal Houston](/r/FrugalHouston)\\n* Higher Education:\\n  * [University of Houston](/r/UniversityOfHouston)\\n  * [Reddit@UH Club](https://www.facebook.com/RedditatUH)\\n  * [University of Houston Downtown](/r/uhd)\\n  * [Rice University](/r/riceuniversity)\\n  * [University of St. Thomas](/r/stthomas)\\n  * [University of Houston Law Center ](/r/uhlc)\\n  * [Texas Southern University](/r/TexasSouthern/)\\n* Fitness/Recreation:\\n  * [Houston Soccer](/r/houstonsoccer)\\n  * [Houston Bicycling](/r/bikehouston)\\n  * [Houston Guns](/r/HoustonGuns)\\n* Sports Teams:\\n  * [Texans Football](/r/Texans)\\n  * [Astros Baseball](/r/Astros)\\n  * [Rockets Basketball](/r/Rockets)\\n  * [Dynamo Soccer](/r/dynamo)\\n  * [Dash Soccer](/r/Dash)\\n\\n* Nearby Communities:\\n  * [Southeast Texas](/r/setx)\\n  * [Kingwood/Spring/Humble](/r/kingwood)\\n  * [Atascocita](/r/atascocitatx)\\n  * [The Woodlands](/r/thewoodlands)\\n  * [Tomball](/r/tomball)\\n  * [Clearlake/Webster/Nassau Bay](/r/clearlake)\\n  * [Pearland](/r/Pearland)\\n  * [Katy](/r/katy)\\n  * [Sugar Land](/r/SugarLand)\\n  * [Spring Branch](/r/SpringBranch)\\n  * [Cypress](/r/CypressTX)\\n  * [Friendswood](/r/Friendswood)',\n",
              "        'houston', 0]], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xPADEeFf4v-n",
        "outputId": "7d32d708-d501-4f25-9696-7f1d0f46d577"
      },
      "source": [
        "reddit_train_clean_body = redditdf2_clean[\"body\"]\n",
        "reddit_train_clean_subreddit = redditdf2_clean[\"subreddit\"]\n",
        "\n",
        "def stripUrl(body):\n",
        "    for start in [\"ftp\",\"http\", \"www\"]:\n",
        "        loc = body.find(start)\n",
        "        while loc != -1:\n",
        "            end = body.find(\".com \",loc+1)\n",
        "            if end == -1:\n",
        "                end = body.find(\".net \",loc+1)\n",
        "            if end == -1:\n",
        "                end = body.find(\".org \",loc+1)\n",
        "            if end == -1:\n",
        "                end = body.find(\".io \",loc+1)\n",
        "            if end == -1:\n",
        "                end = body.find(\".win \",loc+1)\n",
        "            if end == -1:\n",
        "                end = body.find(\" \",loc+1)\n",
        "            if end == -1:\n",
        "                loc = body.find(start,loc+1)\n",
        "                continue\n",
        "                \n",
        "            L = list(body)\n",
        "            L = L[:loc]+L[end+4:]\n",
        "            body = \"\".join(L)\n",
        "            loc = body.find(start,loc+1)\n",
        "    return body\n",
        "\n",
        "\n",
        "\n",
        "reddit_train_clean_body_new = reddit_train_clean_body.apply(stripUrl)\n",
        "reddit_train_clean_body_new = reddit_train_clean_body_new.str.lower()\n",
        "\n",
        "reddit_train_clean_body_new = reddit_train_clean_body_new.str.replace(\"'\",\"\")\n",
        "reddit_train_clean_body_new = reddit_train_clean_body_new.str.replace(\"\\n\",\" \")\n",
        "\n",
        "reddit_train_clean_body_new = reddit_train_clean_body_new.str.replace('[^a-zA-Z0-9_]', ' ', regex=True)\n",
        "\n",
        "\n",
        "print(reddit_train_clean_body_new)\n",
        "print(reddit_train_clean_subreddit)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0       hc is   not   to the left on income inequality...\n",
            "1          its more just a different kind of bigotry  ...\n",
            "2       look  i had a whole thing typed out explaining...\n",
            "3       making fun of people who complain is ridiculou...\n",
            "4       it doesnt matter if we would not known about i...\n",
            "                              ...                        \n",
            "1028    maybe consider a different dog breed that does...\n",
            "1029    nah  when i do my taxes every year my refund g...\n",
            "1030    ive found myself referring to  this  site a lo...\n",
            "1031        book read  greenmantle by john buchan   re...\n",
            "1032        other subreddits   related links   icon li...\n",
            "Name: body, Length: 1033, dtype: object\n",
            "0              Liberal\n",
            "1       ShitRedditSays\n",
            "2                Games\n",
            "3               cringe\n",
            "4                  3DS\n",
            "             ...      \n",
            "1028              dogs\n",
            "1029          Edmonton\n",
            "1030              RATS\n",
            "1031          hsupport\n",
            "1032           houston\n",
            "Name: subreddit, Length: 1033, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHdHTgwu4xfi",
        "outputId": "91e0032e-e112-4cde-ca64-593df2c5f946"
      },
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "import nltk \n",
        "nltk.download('wordnet')\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "stop_dict=set(['a','able','about','across','after','all','almost','also','am','among','an','and','any','are','as','at','be','because','been','but',\n",
        "           'by','can','cannot','could','dear','did','do','does','either','else','ever','every','for','from','get','got','had','has','have','he',\n",
        "           'her','hers','him','his','how','however','i','if','in','into','is','it','its','just','least','let','like','likely','may','me','might',\n",
        "           'most','must','my','neither','no','nor','not','of','off','often','on','only','or','other','our','own','rather','said','say','says',\n",
        "           'she','should','since','so','some','than','that','the','their','them','then','there','these','they','this','tis','to','too','twas',\n",
        "           'us','wants','was','we','were','what','when','where','which','while','who','whom','why','will','with','would','yet','you','your'])\n",
        "\n",
        "  \n",
        "def lemmatize_and_stopwrds(body):\n",
        "    S = ' '.join([lemmatizer.lemmatize(word) for word in body.split()])\n",
        "    S = ' '.join([word for word in body.split() if word not in stop_dict])\n",
        "    return S\n",
        "\n",
        "reddit_train_clean_body_new = reddit_train_clean_body_new.apply(lemmatize_and_stopwrds)\n",
        "print(reddit_train_clean_body_new)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "0       hc left income inequality minimum wage healthc...\n",
            "1       more different kind bigotry lets forget specia...\n",
            "2       look whole thing typed out explaining cut poin...\n",
            "3       making fun people complain ridiculous complain...\n",
            "4       doesnt matter known didnt see japanese version...\n",
            "                              ...                        \n",
            "1028    maybe consider different dog breed better heat...\n",
            "1029    nah taxes year refund goes pay funny little st...\n",
            "1030    ive found myself referring site lot researchin...\n",
            "1031    book read greenmantle john buchan reader ios d...\n",
            "1032    subreddits related links icon lightbulb genera...\n",
            "Name: body, Length: 1033, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "qprgVl8H1PSV",
        "outputId": "693bb88b-bd28-4177-eec6-2f13af994c5d"
      },
      "source": [
        "reddit_train_clean_body_new.iloc[100]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'president trump becomes reality january 20 2017 take remaining 11 months adjusting fact teddy roosevelt meets ronald reagan economic populism combined unprecedented understanding media surprise hes lived commercial end modern media landscape decades witnessed institutional changes news media cnn 80s 90s become understands media played better candidate perhaps president obama campaign trump denounces establishment two different ways skepticism immigration trade hell win south immigration rust belt trade hrc symbol politician claims act interests represents herself corporate interests behind teddy roosevelt win coalition two types economic populism against two partys base party out step those issues republican party voters go hillary turn out vote trump maybe few stay home blue collar workers rust belt cross parties vote trump instead hillary larger share black democratic voters republicans generation well add michigan wisconsin ohio pennsylvania romneys election hes 270 wins iowa virginia florida well hell win nearly 100 electoral votes apolitical analysis im saying whether good bad thing president trump happening matter time until accept consider means'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hWMKLxwh4zPb",
        "outputId": "114dbc7c-7484-4fa6-93a9-6b60b8142601"
      },
      "source": [
        "redditdf2_clean.shape,reddit_train_clean_body_new.shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1033, 3), (1033,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5MmTbcC43lx"
      },
      "source": [
        "#Subreddit Numbering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aZkucAbM42GY",
        "outputId": "7c07f47a-e488-470f-bc32-7dd74bc6702a"
      },
      "source": [
        "subred = pd.Categorical(redditdf2_clean[\"subreddit\"])\n",
        "subred.codes"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([119, 189,  91, ..., 168, 361, 359], dtype=int16)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uTZAVrOE48Pv",
        "outputId": "d6fbef7e-07bb-4f2c-87d5-372c40c2ed76"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "subred = pd.Categorical(redditdf2_clean[\"subreddit\"])\n",
        "\n",
        "preX = np.c_[reddit_train_clean_body_new,subred.codes]\n",
        "\n",
        "X_train,X_test,y_train,y_test = train_test_split(preX,redditdf2_clean[\"controversiality\"])\n",
        "\n",
        "X_train[2]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['much detracts game cut out half content make more rewarding care both side quests main story distracted side quests making stop caring story characters fact loose side stuff more linear quest lines more important characters far more entertaining story know ciri more vesemir unnecessary characters help jack reward play witcher 3 many characters meet know backstory development expected care many major characters entirely underdeveloped game many insignificant unnamed characters take up 100s hours game destracting getting character development bad design cd need learn cut back times push more more game make better longer',\n",
              "       337], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ymzVwO7y494N",
        "outputId": "9c180e40-57b5-4512-b5af-52933700385f"
      },
      "source": [
        "import tensorflow as tf\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "tokenizer = ks.preprocessing.text.Tokenizer(char_level=False)\n",
        "tokenizer.fit_on_texts(X_train[:,0])\n",
        "X_train_tok = tokenizer.texts_to_matrix(X_train[:,0])\n",
        "X_test_tok = tokenizer.texts_to_matrix(X_test[:,0])\n",
        "\n",
        "X_train_final = np.c_[X_train_tok,X_train[:,1]]\n",
        "X_test_final = np.c_[X_test_tok,X_test[:,1]]\n",
        "X_test_final.shape, X_train_final.shape"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((259, 20846), (774, 20846))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKkyUp2cvDrO"
      },
      "source": [
        "#Building Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0AbBnJKU5e2g",
        "outputId": "caa2c7e8-9b8a-42fc-acb7-3a414d9c6793"
      },
      "source": [
        "#Build models\n",
        "models = []\n",
        "#Logistic Regression\n",
        "models.append(('LR',LogisticRegression(solver='lbfgs', class_weight='balanced', max_iter=10000)))\n",
        "#KNN\n",
        "models.append(('KNN',KNeighborsClassifier()))\n",
        "#Classification and Regression Trees\n",
        "models.append(('CART',DecisionTreeClassifier()))\n",
        "#Support Vector Machine\n",
        "models.append(('SVM',SVC(gamma='auto')))\n",
        "\n",
        "#Evaluating each model\n",
        "results = []\n",
        "names = []\n",
        "seed = 7\n",
        "scores = []\n",
        "stdevs = [] # keep stdev just in casea\n",
        "for name, model in models:\n",
        "  kfold = KFold(n_splits=10, random_state=seed)\n",
        "  cv_results = cross_val_score(model,X_train_final, y_train,cv=kfold,scoring='accuracy')\n",
        "  #cv_results = cross_val_score(model, Xpca_train, y_train,cv=kfold,scoring='accuracy')\n",
        "  results.append(cv_results)\n",
        "  names.append(name)\n",
        "  msg = \"%s:%f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
        "  scores.append(cv_results.mean())\n",
        "  stdevs.append(cv_results.std())\n",
        "  print(msg)\n",
        "\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LR:0.701382 (0.059669)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "KNN:0.574759 (0.057057)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CART:0.627872 (0.064321)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "SVM:0.570846 (0.042081)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwAwgarxLeKi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a966068f-1e34-458e-878b-641d72f4f427"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "model2 = MultinomialNB(alpha=10)\n",
        "model2.fit(X_train_final,y_train)\n",
        "MNB_score = model2.score(X_test_final, y_test)\n",
        "\n",
        "clf = BernoulliNB()\n",
        "clf.fit(X_train_final,y_train)\n",
        "BNB_Score = clf.score(X_test_final,y_test)\n",
        "\n",
        "print(\"Multinomial NB score is: \", MNB_score)\n",
        "print(\"Bernoulli NB score is: \", BNB_Score)\n",
        "\n",
        "results.append(MNB_score)\n",
        "results.append(BNB_Score)\n",
        "names.append(\"MNB\")\n",
        "names.append(\"BNB\")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Multinomial NB score is:  0.6216216216216216\n",
            "Bernoulli NB score is:  0.637065637065637\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkLRwMfX0iZE"
      },
      "source": [
        "del results[6]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MG9wkS2-zTfg",
        "outputId": "418c0ee9-02db-4dcf-bcbb-e81797bc3cb0"
      },
      "source": [
        "print(results)\n",
        "print(names)\n",
        "\n",
        "scores.append(MNB_score)\n",
        "scores.append(BNB_Score)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[array([0.62820513, 0.71794872, 0.80769231, 0.78205128, 0.7012987 ,\n",
            "       0.74025974, 0.61038961, 0.67532468, 0.66233766, 0.68831169]), array([0.69230769, 0.61538462, 0.57692308, 0.55128205, 0.58441558,\n",
            "       0.58441558, 0.58441558, 0.58441558, 0.46753247, 0.50649351]), array([0.66666667, 0.61538462, 0.69230769, 0.56410256, 0.63636364,\n",
            "       0.75324675, 0.64935065, 0.51948052, 0.57142857, 0.61038961]), array([0.61538462, 0.58974359, 0.62820513, 0.61538462, 0.54545455,\n",
            "       0.5974026 , 0.54545455, 0.49350649, 0.54545455, 0.53246753]), 0.6216216216216216, 0.637065637065637]\n",
            "['LR', 'KNN', 'CART', 'SVM', 'MNB', 'BNB']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-t1g1aM6Hgtt"
      },
      "source": [
        "# Boxplots"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "id": "AOwEWZ2yxO1M",
        "outputId": "f3cc9a14-617b-4aaf-897a-2b8a3787ab91"
      },
      "source": [
        "fig = plt.figure()\n",
        "fig.suptitle('Algorithm Comparison')\n",
        "ax = fig.add_subplot(111)\n",
        "#plt.boxplot(results, MNB_score, BNB_Score)\n",
        "plt.boxplot(results)\n",
        "ax.set_xticklabels(names)\n",
        "plt.show()\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yo6bNrxntnhO",
        "outputId": "d5f9b5c7-58d7-4746-f796-e06717cd4f9a"
      },
      "source": [
        "print(names)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['LR', 'KNN', 'CART', 'SVM', 'MNB', 'BNB']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RiAX_l9I1hFf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfcb1f9f-288a-49e4-ca61-e61d45b4cf1e"
      },
      "source": [
        "LR = LogisticRegression(solver='lbfgs', class_weight='balanced', max_iter=10000)\n",
        "LR.fit (X_train_final, y_train)\n",
        "predictions = LR.predict (X_test_final)\n",
        "print(accuracy_score(y_test, predictions))\n",
        "print(confusion_matrix (y_test, predictions))\n",
        "print(classification_report(y_test, predictions))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6984732824427481\n",
            "[[ 80  48]\n",
            " [ 31 103]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.62      0.67       128\n",
            "           1       0.68      0.77      0.72       134\n",
            "\n",
            "    accuracy                           0.70       262\n",
            "   macro avg       0.70      0.70      0.70       262\n",
            "weighted avg       0.70      0.70      0.70       262\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDEnqBPp9T6F",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "outputId": "836e2ba5-0691-477b-a8c9-f2fe0a64ea8e"
      },
      "source": [
        "#Definition of the DNN model\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "\n",
        "model3 = Sequential()\n",
        "\n",
        "#model3.add(BatchNormalization())\n",
        "#model3.add(BatchNormalization())\n",
        "model3.add(Dense(256, activation='relu'))\n",
        "model3.add(Dense(43, activation='softmax'))\n",
        "\n",
        "#Compilation of the model\n",
        "model3.compile(\n",
        "    loss='categorical_crossentropy', \n",
        "    optimizer='adam', \n",
        "    metrics=['accuracy']\n",
        ")\n",
        "New_X_test_final = np.asarray(X_test_final).astype(np.float32)\n",
        "New_y_test = np.asarray(y_test).astype(np.float32)\n",
        "epochs = 20\n",
        "history = model3.fit(X_train_final, y_train, batch_size=16, epochs=epochs,\n",
        "validation_data=(New_X_test_final, New_y_test))\n",
        "\n",
        "#Display of the accuracy and the loss values\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(0)\n",
        "plt.plot(history.history['accuracy'], label='training accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='val accuracy')\n",
        "plt.title('Accuracy')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure(1)\n",
        "plt.plot(history.history['loss'], label='training loss')\n",
        "plt.plot(history.history['val_loss'], label='val loss')\n",
        "plt.title('Loss')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-3bb2346b6de5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m history = model3.fit(X_train_final, y_train, batch_size=16, epochs=epochs,\n\u001b[0;32m---> 23\u001b[0;31m validation_data=(New_X_test_final, New_y_test))\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m#Display of the accuracy and the loss values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1120\u001b[0m           \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m           \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1122\u001b[0;31m           steps_per_execution=self._steps_per_execution)\n\u001b[0m\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m       \u001b[0;31m# Container that configures and calls `tf.keras.Callback`s.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36mget_data_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1346\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_cluster_coordinator\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_ClusterCoordinatorDataHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mDataHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute)\u001b[0m\n\u001b[1;32m   1148\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m         \u001b[0mdistribution_strategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1150\u001b[0;31m         model=model)\n\u001b[0m\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    229\u001b[0m                **kwargs):\n\u001b[1;32m    230\u001b[0m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensorLikeDataAdapter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_tensorlike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m     sample_weight_modes = broadcast_sample_weight_modes(\n\u001b[1;32m    233\u001b[0m         sample_weights, sample_weight_modes)\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m_process_tensorlike\u001b[0;34m(inputs)\u001b[0m\n\u001b[1;32m   1028\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1029\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1030\u001b[0;31m   \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_convert_numpy_and_scipy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1031\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_to_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 867\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    868\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    869\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 867\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    868\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    869\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m_convert_numpy_and_scipy\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1023\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloating\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloatx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1025\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1026\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0m_is_scipy_sparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1027\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_scipy_sparse_to_sparse_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor_v2_with_dispatch\u001b[0;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[1;32m   1429\u001b[0m   \"\"\"\n\u001b[1;32m   1430\u001b[0m   return convert_to_tensor_v2(\n\u001b[0;32m-> 1431\u001b[0;31m       value, dtype=dtype, dtype_hint=dtype_hint, name=name)\n\u001b[0m\u001b[1;32m   1432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor_v2\u001b[0;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[1;32m   1439\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1440\u001b[0m       \u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype_hint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1441\u001b[0;31m       as_ref=False)\n\u001b[0m\u001b[1;32m   1442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/profiler/trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtrace_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1565\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1566\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1567\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1568\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/tensor_conversion_registry.py\u001b[0m in \u001b[0;36m_default_conversion_function\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_default_conversion_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mdel\u001b[0m \u001b[0mas_ref\u001b[0m  \u001b[0;31m# Unused.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    263\u001b[0m   \"\"\"\n\u001b[1;32m    264\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0;32m--> 265\u001b[0;31m                         allow_broadcast=True)\n\u001b[0m\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    274\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tf.constant\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m   \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m   \u001b[0;34m\"\"\"Implementation of eager constant.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m   \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m     96\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type float)."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dB3YHI5f5U7O"
      },
      "source": [
        "#Only use if there are memory issue"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zeVZz4oS5CbK"
      },
      "source": [
        "from sklearn.decomposition import TruncatedSVD\n",
        "\n",
        "tsvd = TruncatedSVD(n_components = 100)\n",
        "Xpca_train = tsvd.fit_transform(X_train_final) ## autocentered\n",
        "Xpca_test =  tsvd.transform(X_test_final) ## autocentered\n",
        "Xpca_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D5V1y8ab5JUE",
        "outputId": "37a87479-ef86-42b1-e565-1ae2c57065fb"
      },
      "source": [
        "clf.fit(Xpca_train,y_train)\n",
        "\n",
        "clf.score(Xpca_test,y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5637065637065637"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    }
  ]
}